{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4b0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a601253",
   "metadata": {},
   "source": [
    "# What we know:\n",
    "\n",
    "#### The kaggle provided dataset contains 3 files:  \n",
    "##### comment_to_score.csv\n",
    "    - Contains all unranked comments. Our objective is to rank these comments based off the toxicity, with 1 being the most toxic. \n",
    "\n",
    "##### sample_submission.csv\n",
    "    - Contains an example of how the submission should look like... Not sure if this will help with training?\n",
    "\n",
    "##### validation_data.csv\n",
    "    - According to kaggle this is the \"pair rankings that can be used to validate models. Includes annotator work id and how the annotator ranked a given pair of comments\"\n",
    "    \n",
    "# Understanding the objective\n",
    "Before moving on, let's take a moment and understand what our overall objective is: \n",
    "We want to rank a list of comments base off of the level of toxicity without the use of any provided training data. However, while we do not have training data, we have provided validation data, which includes a set of toxicity rankings that might help to validate models.\n",
    "\n",
    "# Understanding our data:\n",
    "In the next few lines, we will import our data and see what we're actually dealing with and see if the data provided is actually useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142faa9",
   "metadata": {},
   "source": [
    "#### comments_to_score.csv\n",
    "        - We knew how the data looked like before, but let's take a closer look and see what might need to be cleaned up  \n",
    "   \n",
    "   - Column Names\n",
    "       - comment_id (comment identifier)\n",
    "       - text (actual text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf8fe35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      " \n",
      "\n",
      "Gjalexei, you asked about whether there is an \"\"anti-editorializing\"\" policy here.  There is, and it's called wikipedia:neutral point of view.  It discusses at some length  the case of what we should do when writing about a subject which most of us find repugnant.  Whilst you're not likely to get too many defenders of FGM here, the need for the policy should be clearer for articles like abortion, for instance.\n",
      "\n",
      "If something you write is edited and you're not sure why, please continue to question such edits on the talk page.  Sometimes, you'll learn more about wikipedia policy.  Sometimes, you'll find out that some other people working on here can get it flat-out wrong ) Robert Merkel\"\n"
     ]
    }
   ],
   "source": [
    "# comments_to_score data\n",
    "df = pd.read_csv(\"./data/comments_to_score.csv\")\n",
    "eg1 = df.text[0]\n",
    "print(eg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b21869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\n",
      "I already gave you the source for all my edits   The Slur database, so I will not continue to play your little game. If you weren't so lazy and intent on harassment, you could use Google to search for \"\"Gargamel\"\" and \"\"Jew\"\". You get more than 400 hits including white supremacist sites and an academic paper dating to 1996. It's obviously a real slur with some usage. Nice try at being obdurate though. I'm sure there's a slur that describes that characteristic. Shyster doesn't quite cover it.  22:08, 22 Dec 2004 (UTC)\"\n"
     ]
    }
   ],
   "source": [
    "eg2 = df.text[25]\n",
    "print(eg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14235b9b",
   "metadata": {},
   "source": [
    "##### took two comments from the provided dataset. We can make a few observations based off of the content of the texts:   \n",
    "  \n",
    "- First, punctuation. Normally, when we deal with datasets that involve texts, we would ignore punctuation. Howevever, knowing the habits of the internet, the punctuation can reflect toxicity. For instance, quotation marks have been used to represent sarcasm.\n",
    "    -Building onto this, this same concept applies with capitalized letters. Generally speaking, when dealing with texts, we would try to make the letters consistent. However, given the habits of the internet, we can \n",
    "    \n",
    "- I believe we can consider the second comment to be more toxic. But let's try to understand what makes it toxic: \n",
    "    - \"If you weren't so lazy and intent on harassment, you could use Google to search for \"\"Gargamel\"\" and \"\"Jew\"\"\". \n",
    "        - This particular sentence feels targeted, with lazy being the negative description.   \n",
    "        - Might want to consider pulling common words, phrases, and general patterns with the provided validation dataset as a means to start. However, keep in mind that the dataset also contains data that is not in our testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770d263",
   "metadata": {},
   "source": [
    "###### Validation_data.csv\n",
    "After playing around with the data, I've come to realize the order of the comments do not matter. As described on Kaggle, this ia a collection of comments, which a person judged a pair of comments to see which one is more or less toxic (making almost binary). The comments are kinda hilarious from a third person perspective.  \n",
    "  \n",
    "Looking at the data on excel, I noticed that some comments are repeated, showing that it's been consistently rated as being more toxic than the other. It might be interesting to make a histogram based off of the number times a comment is rated as toxic. We can also create a list of toxic comments and have it ordered from most toxic to least toxic based off the number of counts it was rated as more toxic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1a9047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worker                                                      313\n",
       "less_toxic              This article sucks \\n\\nwoo woo wooooooo\n",
       "more_toxic    WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd = pd.read_csv(\"./data/validation_data.csv\")\n",
    "eg3 = vd.loc[0,:]\n",
    "eg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c40f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worker                                                       46\n",
       "less_toxic                           I'm Jim,a retarded idiot .\n",
       "more_toxic     You are a nazi. \\n\\nYour defense of the Latin...\n",
       "Name: 100, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg4 = vd.loc[100,:]\n",
    "eg4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9dd66",
   "metadata": {},
   "source": [
    "##### sample_submission.csv\n",
    "This simply tells us how we should make our submission, it is interesting that we only care about the comment_id and the score. Although I am more interested in how the score will be developed. Is it unique or what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ecbc9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2452675</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id  score\n",
       "0      114890    0.5\n",
       "1      732895    0.5\n",
       "2     1139051    0.5\n",
       "3     1434512    0.5\n",
       "4     2084821    0.5\n",
       "5     2452675    0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg5 = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "eg5.loc[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7845a77",
   "metadata": {},
   "source": [
    "### Testing out Ideas\n",
    "\n",
    "In the previous section, I discussed ideas to explore. In this section, we will try out those ideas and see how they could apply to our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce0c6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find all the unique comments in the validation dataset. \n",
    "\n",
    "# Alright, so I want to look at this data with ease. To save time and memory, I'm going to give each unique comment a unique number\n",
    "# And count the number of occurences the unique ID has. \n",
    "toxic_unique = vd.more_toxic.unique()\n",
    "toxic_dict = {};\n",
    "not_toxic_unique = vd.less_toxic.unique()\n",
    "not_toxic_dict = {};\n",
    "count = 0;\n",
    "\n",
    "for tword in toxic_unique:\n",
    "    toxic_dict[count] = [tword, len(vd.index[vd.more_toxic == tword].tolist())]\n",
    "    count += 1\n",
    "    # Create a dictionary that we can use\n",
    "    #I don't know how much time or memory this uses, but basicaly I am creating a dictionary which stores the number of counts per unique comment\n",
    "\n",
    "count = 0\n",
    "for ntword in not_toxic_unique:\n",
    "    not_toxic_dict[count] = [ntword, len(vd.index[vd.less_toxic == ntword].tolist())] # Create a dictionary that we can use\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f8aca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>YOU SUCK \\n\\nI HATE YOU&gt; YOU CAN FUCK MY ASS ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>STUPID SPANISH CENTRALISTSTUPID SPANISH CENTRA...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>MORON! The USA has only 5% of the worlds popul...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>LAST WARNING YOU FUCKING TOSSER, IT TAKES ME 1...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>Imma cut off ur nutz and send em to ur gf \\n\\...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>PEOPLE ON THIS SITE SUCK  \\n\\nPEOPLE ON THIS ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>\"\\n\\nBastard Child\\nDoes anyone know if Obama ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>INTEVIEW \\n\\nME: ARE YOU GAY?\\n\\nABE GAY DASH...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>YOU'RE A FUCKING LIAR WHO DOESN'T KNOW HOW TO ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>ScJessey is a Big Fat Faggot Pinko Commie Asshole</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>go to hell \\n\\ngo to hell and leave me alone</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Ok, what is it \\n\\nWhy are you such a queer.....</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>Why don't you just fuck off?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>Missrain4, I will make a rain of cum on your f...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>Gonna fuck you up \\n\\nYou little bitch. 86.17...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>fuck you jzg \\n\\ni will have you removed as ed...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>Fuck you, Smith.  Please have me notified when...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>MOTHERFUCKER, DONT BE CHANGING THE FUCKING GTA...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>\"\\nNo, I'm not joking.  I'm hoping to help BD ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>Stupidhead! Dweeb! How dare you say that! Scor...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  count\n",
       "3603   YOU SUCK \\n\\nI HATE YOU> YOU CAN FUCK MY ASS ...     14\n",
       "905   STUPID SPANISH CENTRALISTSTUPID SPANISH CENTRA...     14\n",
       "788   MORON! The USA has only 5% of the worlds popul...     12\n",
       "1247  LAST WARNING YOU FUCKING TOSSER, IT TAKES ME 1...     12\n",
       "1990   Imma cut off ur nutz and send em to ur gf \\n\\...     12\n",
       "1516   PEOPLE ON THIS SITE SUCK  \\n\\nPEOPLE ON THIS ...     12\n",
       "4523  \"\\n\\nBastard Child\\nDoes anyone know if Obama ...     12\n",
       "2130   INTEVIEW \\n\\nME: ARE YOU GAY?\\n\\nABE GAY DASH...     12\n",
       "563   YOU'RE A FUCKING LIAR WHO DOESN'T KNOW HOW TO ...     12\n",
       "695   ScJessey is a Big Fat Faggot Pinko Commie Asshole     12\n",
       "5244     go to hell \\n\\ngo to hell and leave me alone       12\n",
       "1993   Ok, what is it \\n\\nWhy are you such a queer.....     11\n",
       "2683                       Why don't you just fuck off?     11\n",
       "4836  Missrain4, I will make a rain of cum on your f...     11\n",
       "2760   Gonna fuck you up \\n\\nYou little bitch. 86.17...     11\n",
       "5281  fuck you jzg \\n\\ni will have you removed as ed...     11\n",
       "3048  Fuck you, Smith.  Please have me notified when...     11\n",
       "7791  MOTHERFUCKER, DONT BE CHANGING THE FUCKING GTA...     11\n",
       "2714  \"\\nNo, I'm not joking.  I'm hoping to help BD ...     11\n",
       "2621  Stupidhead! Dweeb! How dare you say that! Scor...     11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df = pd.DataFrame.from_dict(toxic_dict, orient = 'index', columns = ['text', 'count']).sort_values(by =['count'], ascending = False)\n",
    "not_toxic_df = pd.DataFrame.from_dict(not_toxic_dict, orient = 'index', columns = ['text', 'count']).sort_values(by = ['count'], ascending = False)\n",
    "\n",
    "toxic_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2a3898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>How many sockpuppets do you have?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>sorry i jumped to conclusions \\n\\non christia...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>Sockpuppet\\nHi, would you please confirm this ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>I erased your cuss word\\nFrom: some random per...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>An addition comment of interest by Andrew Coyn...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>this irishtom guy is turning every article int...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>Please no Wiki-Weirdo posts !</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383</th>\n",
       "      <td>the fife shuffle \\n\\naahh dismas surely you a...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>\"\\n\\n Please stop your disruptive editing. If ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>You are not sorry one damned bit.  You have ye...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821</th>\n",
       "      <td>You vandalized the Flavor of Love acticle. Sto...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>Hello \\n\\nOK, don't try to frighten me with y...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>are you proud to be propaganda tool puppet of ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Support- stops the POV of nationalist editors</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>Never physical harm. Since you're directly con...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7071</th>\n",
       "      <td>this still should not stop me editing my page....</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4052</th>\n",
       "      <td>That's pretty damn cool, an old medievil town,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>\" 2009 (UTC)\\n\\nWould it be possible to sugges...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>\"Please do not add nonsense to Wikipedia. It i...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>yo  \\n\\nyou could at least reply to my messag...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  count\n",
       "5422                 How many sockpuppets do you have?      13\n",
       "786    sorry i jumped to conclusions \\n\\non christia...     13\n",
       "2192  Sockpuppet\\nHi, would you please confirm this ...     12\n",
       "4930  I erased your cuss word\\nFrom: some random per...     12\n",
       "4021  An addition comment of interest by Andrew Coyn...     12\n",
       "6612  this irishtom guy is turning every article int...     12\n",
       "4646                      Please no Wiki-Weirdo posts !     11\n",
       "9383   the fife shuffle \\n\\naahh dismas surely you a...     11\n",
       "1401  \"\\n\\n Please stop your disruptive editing. If ...     11\n",
       "4043  You are not sorry one damned bit.  You have ye...     11\n",
       "7821  You vandalized the Flavor of Love acticle. Sto...     11\n",
       "4229   Hello \\n\\nOK, don't try to frighten me with y...     11\n",
       "2174  are you proud to be propaganda tool puppet of ...     11\n",
       "860    Support- stops the POV of nationalist editors        11\n",
       "7300  Never physical harm. Since you're directly con...     11\n",
       "7071  this still should not stop me editing my page....     11\n",
       "4052  That's pretty damn cool, an old medievil town,...     11\n",
       "6267  \" 2009 (UTC)\\n\\nWould it be possible to sugges...     10\n",
       "579   \"Please do not add nonsense to Wikipedia. It i...     10\n",
       "1741   yo  \\n\\nyou could at least reply to my messag...     10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_toxic_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "affc4411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_df length:  11678\n",
      "not_toxic_df length:  11532\n"
     ]
    }
   ],
   "source": [
    "print(\"toxic_df length: \", len(toxic_df))\n",
    "print(\"not_toxic_df length: \", len(not_toxic_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e85d4d",
   "metadata": {},
   "source": [
    "As you can see, I created two different dataframes to rank the frequency of comments found in the toxic and less toxic columns from the validity data provided. One thing to keep in mind is that we will want our algorithm to generalize, therefore having a keyword classifer might not be particularly useful. Instead of looking for specific words, we should think about the underlying trends in the data.      \n",
    "  \n",
    "Interestingly, in the toxic column, a lot of the comments use an abundance of capital letters. Furthermore, comments deemed more toxic seem to have more misspelling, slang, and punctuation. Of course, this type of identification is for the most obvious cases. However, this leads me to wonder if we can apply an algorithm to identify underlying trends.   \n",
    "  \n",
    "I almost glossed over one thing: The goal of this project is to rank the comments from most toxic to least toxic. As explained in the project description, it is very difficult to rank a list of comments entirely. Instead, it is a lot easier to judge two comments and rank which one is toxic. I should keep this in mind when I'm building my future algorithm. Instead of loading the entire dataset into my model, it might be better to use a sliding window method that takes in two comments and spits out which one is considered more toxic. This leads me to think that a binary classifier might be particularly useful. However, how would we identify the unlabeled features? Hmmm.... How much natural language processing is actually necessary here?\n",
    "  \n",
    "On a side note, I think it might be interesting to see the amount of overlap between the two classes (more toxic vs less toxic)\n",
    "I find it funny that there's more toxic comments than not toxic comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5212a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_df = {}\n",
    "un_not_toxic_df = {}\n",
    "\n",
    "\n",
    "count = 0\n",
    "ncount = 0\n",
    "\n",
    "for i in range(len(not_toxic_df.text)):\n",
    "    ntword = not_toxic_df.text[i]\n",
    "    ntcount = not_toxic_df['count'][i]\n",
    "\n",
    "    if ntword in list(toxic_df.text):\n",
    "        t_idx = (toxic_df.index[toxic_df.text == ntword].tolist())[0]\n",
    "        t_count = toxic_df['count'][t_idx]\n",
    "        tword = toxic_df['text'][t_idx]\n",
    "        common_df[count] = [ntword, ntcount, t_count]\n",
    "        count += 1\n",
    "        \n",
    "    else:\n",
    "        un_not_toxic_df[ncount] = [ntword, ntcount]\n",
    "        ncount += 1\n",
    "        \n",
    "common_df = pd.DataFrame.from_dict(common_df, orient = 'index', columns = ['text', 'ntcount', 'tcount'])\n",
    "un_not_toxic_df = pd.DataFrame.from_dict(un_not_toxic_df, orient = 'index', columns = ['text', 'count']).sort_values(by = ['count'], ascending = False)\n",
    "un_not_toxic_df = un_not_toxic_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85ff9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "un_toxic_df = {}\n",
    "\n",
    "for i in range(len(toxic_df)):\n",
    "    tword = toxic_df.text[i]\n",
    "    if tword not in list(common_df.text):\n",
    "        tcount = toxic_df['count'][i]\n",
    "        un_toxic_df[count] = [tword, tcount]\n",
    "        count += 1\n",
    "\n",
    "un_toxic_df = pd.DataFrame.from_dict(un_toxic_df, orient = 'index', columns = ['text', 'count']).sort_values(by = ['count'], ascending = False)\n",
    "un_toxic_df = un_toxic_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed132d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  ntcount  tcount\n",
      "302   STUPID SPANISH CENTRALISTSTUPID SPANISH CENTRA...        1      14\n",
      "7223   YOU SUCK \\n\\nI HATE YOU> YOU CAN FUCK MY ASS ...        1      14\n",
      "299   ScJessey is a Big Fat Faggot Pinko Commie Asshole        3      12\n",
      "6370   Imma cut off ur nutz and send em to ur gf \\n\\...        3      12\n",
      "759   \"\\nNo, I'm not joking.  I'm hoping to help BD ...        4      11\n",
      "1116  Fuck you, Smith.  Please have me notified when...        1      11\n",
      "2973   Gonna fuck you up \\n\\nYou little bitch. 86.17...        1      11\n",
      "3768  Missrain4, I will make a rain of cum on your f...        1      11\n",
      "4623  MOTHERFUCKER, DONT BE CHANGING THE FUCKING GTA...        1      11\n",
      "4791                      |decline=Fucking bellend —           1      11\n",
      "\n",
      "shared comments count:  8959\n",
      "toxic comments total:  11678\n",
      "less toxic comments total:  11532\n",
      "% of overlap for toxic:  76.7\n",
      "% of overlap for less toxic:  77.7\n"
     ]
    }
   ],
   "source": [
    "common_df = common_df.sort_values(by = ['tcount', 'ntcount'], ascending = False)\n",
    "print(common_df[0:10])\n",
    "print(\"\\nshared comments count: \", len(common_df))\n",
    "print(\"toxic comments total: \", len(toxic_df))\n",
    "print(\"less toxic comments total: \", len(not_toxic_df))\n",
    "print(\"% of overlap for toxic: \", (round(len(common_df)/len(toxic_df),3)*100))\n",
    "print(\"% of overlap for less toxic: \", (round(len(common_df)/len(not_toxic_df),3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7afe6",
   "metadata": {},
   "source": [
    "This is interesting... There is a huge overlap between our more toxic and less toxic comments. Furthermore, the percentage of overlap is similar in both cases, with 76.7% overlap for toxic and 77.7% for less toxic which makese sense given that both datasets are similar sizes. This also tells me that close to 25% of each dataset is uniquely toxic and not toxic, which is also worth exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02d51ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniquely Toxic Comments, length:  2719\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go to hell \\n\\ngo to hell and leave me alone</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAST WARNING YOU FUCKING TOSSER, IT TAKES ME 1...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"\\n\\nBastard Child\\nDoes anyone know if Obama ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOU'RE A FUCKING LIAR WHO DOESN'T KNOW HOW TO ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTEVIEW \\n\\nME: ARE YOU GAY?\\n\\nABE GAY DASH...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MORON! The USA has only 5% of the worlds popul...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PEOPLE ON THIS SITE SUCK  \\n\\nPEOPLE ON THIS ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>suck my dick irish guy you faggot</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YOU ARE A FUCKING NERD. GO KILL YOURSELF YOU N...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You dummasses, I DID SAY THE DAMN RIGHT STUFF...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  count\n",
       "0     go to hell \\n\\ngo to hell and leave me alone       12\n",
       "1  LAST WARNING YOU FUCKING TOSSER, IT TAKES ME 1...     12\n",
       "2  \"\\n\\nBastard Child\\nDoes anyone know if Obama ...     12\n",
       "3  YOU'RE A FUCKING LIAR WHO DOESN'T KNOW HOW TO ...     12\n",
       "4   INTEVIEW \\n\\nME: ARE YOU GAY?\\n\\nABE GAY DASH...     12\n",
       "5  MORON! The USA has only 5% of the worlds popul...     12\n",
       "6   PEOPLE ON THIS SITE SUCK  \\n\\nPEOPLE ON THIS ...     12\n",
       "7                  suck my dick irish guy you faggot      9\n",
       "8  YOU ARE A FUCKING NERD. GO KILL YOURSELF YOU N...      9\n",
       "9   You dummasses, I DID SAY THE DAMN RIGHT STUFF...      9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Uniquely Toxic Comments, length: \", len(un_toxic_df))\n",
    "un_toxic_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e488376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniquely Not Toxic Comments, length:  2573\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An addition comment of interest by Andrew Coyn...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sockpuppet\\nHi, would you please confirm this ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, anything else inserted here will be removed</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ru-sib \\n\\nThe number of bots increases. You ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\".\\n\\n\"\"This emphasis also led Boas to conclud...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\n The above argument \\n\\nI just discerned ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"\\nSahih Hadith are only second in authority a...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How is that vandalism? \\n\\nI'm the most recen...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BTW \\n\\nI've noticed your page, and with all ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you want to post rubbish about Meyer Moran ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  count\n",
       "0  An addition comment of interest by Andrew Coyn...     12\n",
       "1  Sockpuppet\\nHi, would you please confirm this ...     12\n",
       "2      , anything else inserted here will be removed      9\n",
       "3   ru-sib \\n\\nThe number of bots increases. You ...      9\n",
       "4  \".\\n\\n\"\"This emphasis also led Boas to conclud...      9\n",
       "5  \"\\n\\n The above argument \\n\\nI just discerned ...      9\n",
       "6  \"\\nSahih Hadith are only second in authority a...      9\n",
       "7   How is that vandalism? \\n\\nI'm the most recen...      9\n",
       "8   BTW \\n\\nI've noticed your page, and with all ...      9\n",
       "9  If you want to post rubbish about Meyer Moran ...      9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Uniquely Not Toxic Comments, length: \", len(un_not_toxic_df))\n",
    "un_not_toxic_df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4b1da",
   "metadata": {},
   "source": [
    "I believe looking at this new data supports what I was saying previously, which is that all caps comments are a great way to identify toxic comments. However, as I said before, this will only help to discern the most obvious cases. This remains true with regarding less toxic comments and proper grammar. Later, as I build my model, I should keep in mind ways to check for proper spelling and grammar. \n",
    "\n",
    "If I think about this in larger scenario, should I create my own scoring method. This might help with unsupervised learning. For example, I could add points per word that is in all caps, which w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a76e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
